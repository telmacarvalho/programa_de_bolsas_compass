{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apache Spark"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Etapa 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instruções"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inicialmente iremos preparar o ambiente, definindo o diretório onde nosso código será desenvolvido. Para este diretório iremos copiar o arquivo nomes_aleatorios.txt.\n",
    "\n",
    "Após, em nosso script Python, devemos importar as bibliotecas necessárias:\n",
    "\n",
    "```\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "from pyspark import SparkContext, SQLContext\n",
    "```\n",
    "Aplicando as bibliotecas do Spark, podemos definir a Spark Session e sobre ela definir o Context para habilitar o módulo SQL\n",
    "\n",
    "```spark = SparkSession \\\n",
    "\n",
    "                .builder \\\n",
    "\n",
    "                .master(\"local[*]\")\\\n",
    "\n",
    "                .appName(\"Exercicio Intro\") \\\n",
    "\n",
    "                .getOrCreate()```\n",
    "\n",
    "Nesta etapa, adicione código para ler o arquivo nomes_aleatorios.txt através do comando spark.read.csv. Carregue-o para dentro de um dataframe chamado df_nomes e, por fim, liste algumas linhas através do método show. Exemplo: df_nomes.show(5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Código"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+\n",
      "|             _c0|\n",
      "+----------------+\n",
      "|    David Staten|\n",
      "|  Heather Rivera|\n",
      "|     Lester Wood|\n",
      "|William Sandoval|\n",
      "| Gwendolyn Hines|\n",
      "+----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Importa a biblioteca findspark para iniciar o serviço do Spark na máquina que hospeda o meu notebook\n",
    "import findspark\n",
    "findspark.init()\n",
    "import pyspark\n",
    "\n",
    "# Importa demais bibliotecas necessárias\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkContext, SQLContext\n",
    "\n",
    "# Aplica as bibliotefcas do spark\n",
    "spark = SparkSession\\\n",
    "    .builder\\\n",
    "    .master(\"local[*]\")\\\n",
    "    .appName(\"Exercicio Intro\")\\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Lê o arquivo de texto\n",
    "df_nomes = spark.read.csv(\"Files/nomes_aleatorios.txt\")\n",
    "\n",
    "# Exibe 5 linhas do dataframe\n",
    "df_nomes.show(5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Etapa 2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instruções"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No Python, é possível acessar uma coluna de um objeto dataframe pelo atributo (por exemplo df_nomes.nome) ou por índice (df_nomes['nome']). Enquanto a primeira forma é conveniente para a exploração de dados interativos, você deve usar o formato de índice, pois caso algum nome de coluna não esteja de acordo seu código irá falhar.\n",
    "\n",
    "Como não informamos no momento da leitura do arquivo, o Spark não identificou o Schema por padrão e definiu todas as colunas como string. Para ver o Schema, use o método df_nomes.printSchema().\n",
    "\n",
    "Nesta etapa, será necessário adicionar código para renomear a coluna para Nomes, imprimir o esquema e mostrar 10 linhas do dataframe."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Código"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Nomes: string (nullable = true)\n",
      "\n",
      "+------------------+\n",
      "|             Nomes|\n",
      "+------------------+\n",
      "|      David Staten|\n",
      "|    Heather Rivera|\n",
      "|       Lester Wood|\n",
      "|  William Sandoval|\n",
      "|   Gwendolyn Hines|\n",
      "|Constance Mcmillan|\n",
      "|        Billy Diaz|\n",
      "|      Marcos Rolfe|\n",
      "|         Cara Cole|\n",
      "|         John Gant|\n",
      "+------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Renomeia a coluna para Nomes\n",
    "df_nomes = df_nomes.withColumnRenamed(\"_c0\", \"Nomes\")\n",
    "# Exibe o esquema\n",
    "df_nomes.printSchema()\n",
    "# Exibe 10 linhas do dataframe\n",
    "df_nomes.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
